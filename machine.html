<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Teachable Machines</title>
    <link rel="stylesheet" href="stylepage.css">
</head>

<body>
    <!--Main navigation bar-->
    <header>
        <nav>
            <ul>
                <!--Clickable text to reference to other pages-->
                <li><a href="index.html">Home</a></li>
                <li><a href="about.html">About Us</a></li>
                <li><a href="resources.html">Resources</a></li>
                <li><a href="techhero.html">Tech Heroes</a></li>
                <li><a href="machine.html">Teachable Machines</a></li>
            </ul>
        </nav>
    </header>

    <h1>Teachable Machines</h1>
    
    <table>
        <tr>
            <th>Project Statement</th> 
        </tr>
        <td>
            <p class="statement-header">Bias and Discrimination</p>
            <p>In “Unmasking AI,” we learned about algorithmic bias and how it favors some users while marginalizing others. Buolawmini talks about her experience with the white mask on how the face recognition software would only detect her face when she puts on the white mask. When she is not wearing the white mask, the software could not detect her dark-skinned face. Furthermore, Buolawmini also highlights how there are gender biases as well. Companies would filter out resumes or applications if it detected that the applicants were women. This was due to the data that the model was trained on. It highly favored men as opposed to women.
            </p>
            <p>In training our model, we realized that it is crucial to diversify the training data that we provided to the model. Without it, the algorithm might perform better for some users while marginalizing others. To do this, we diversified our data of facial recognition by providing multiple images of people with different skin color types, ethnicity, and gender. By doing so, the model will be better able to detect different types of faces regardless of skin color, ethnicity, and gender. We tried to the best of our ability to eliminate any type of algorithmic biases when detecting faces in our model.
            </p>
            
            <p class="statement-header">Transparency and Accountability</p>
            <p>Unmasking AI Buolamwini writes a report about the misuse of AI and bias that amazon had using it. She also found out about an apartment building her family member lived in and had installed cameras that were unfair use.</p>
            <p>Transparency of what these companies or people are doing with artificial intelligence is extremely important. Since there are people that may not understand what exactly is going on with the AI around them they need that transparency so they know what to expect and to speak up if there are things that they believe are wrong. With our project we want people to understand what we are doing and how it works to provide an excellent experience for everyone. That is why we documented our process on how we trained our image model. We also provided videos to show people how to use our image model effectively.</p>
            
            <p class="statement-header">Intersectionality</p>
            <p>Intersectionality is a word that we learned about at the start using in in our first two projects showing how important it is in our class and how it is our overall framework of who we are not just one thing about us but multiple things, and With “Unmasking AI” Buolawini talks about intersectionality not just herself but also in how many companies are using intersectionality and making those issues be apart of AI and be inaccurate in many ways providing an unjust treatment of people. One of these companies Buolawini learned more about their AI use is when Amazon used AI to look at resumes it would eliminate womens resumes more than men even when they were fully qualified for the jobs. Other companies included microsoft and their facial recognition like her facial recognition it was proved to be more accurate in white men.</p>
            <p>With our project we strive to have no bias to provide a fair algorithm to those who use it compared to big tech companies who built their algorithms with many people. </p>
            
            <p class="statement-header">Regulation and Policy</p>
            <p>There is not much regulation for AI on what it can or can't do. In England Police used AI to set up on the streets to use facial recognition on random people walking around and was seen to be very inaccurate and stopped a man just for covering his face. Other problems that this can cause is to those who are people of color putting people in danger of being treated unfairly and risking putting away the wrong people. This is something that needs to be fixed and needs to have regulations and policies for what companies can or cannot do with AI because with technology changing rapidly we risk AI being more independent and risking it being more biased with its own opinions without having anyone stopping it.</p>
            <p>For our model, we chose a variety of images to represent our subjects in order to prevent biases in our model. For example, we chose multiple images of people of different race and skin color, and we also chose multiple varieties of dogs, cars, and trees. We also kept regulation and policy in mind when creating our image model by carefully looking at what data we were feeding our image model.</p>

            <p class="statement-header">In Summary/Lessons learned</p>
            <p>Our project is to change the issues with algorithmic bias with what we learned in the book and throughout this course. All those bias and unequal treatment that AI was doing to others is something we are trying to eliminate fully. Buolamwini's model that had her putting on a mask to be seen is something that we want to make possible without having to change anything about ourselves. It made her search for answers about AI and learn that there were many problems going on with the use of AI and these issues are extremely important on how our model is for everyone to use. She brought attention to those issues for more people to hear about and her speaking out about them made some big tech companies fix issues with their facial recognition and unfairness against some people who were using their algorithms.</p>
            <p>Throughout this course we have read/watched many things about artificial intelligence. There are good things about it and bad things. We have especially learned about how tech companies and their unfair treatment against minorities and against women. Our project is to eliminate those issues. We are taking all problems of those things we have learned from this course and building our model to be the best it can be.
            </p>
            <p>Companies could learn from this and fix issues that Buolamwini found in major tech companies and that we saw across the world because what's the point of providing these services if not everyone can use it.</p>

            <p class="statement-header">Algorithm</p>
            <p>Try out our model for an excellent experience with AI. We have also provided a video of the algorithm at work to help with your experience!</p>
        </td>
    </table>

    <table>
        <tr>
            <th>The Process</th>
        </tr>
        <td>
            <p>We first found photos of our subjects which were pictures of a person, a dog, a car, and a tree. We then imported these photos into the image model and trained the model to recognize these subjects.</p>
            <img src="imagemodel1.png" alt="image model" width="500" height="288">
            <p>After successfully training the model, the image model was able to correctly identify the subject that was presented to it. As can be seen below, the image model correctly identified the dog.</p>
            <img src="imagemodel2.png" alt="image model" width="500" height="286">
        </td>
    </table>

    <table>
        <tr>
            <th>Video</th>
        </tr>
        <td>
            <video width="500" height="956" controls>
                <source src="imagevideo1.mp4" type="video/mp4">
            </video>
            <video width="500" height="393" controls>
                <source src="imagevideo2.mp4" type="video/mp4">
            </video>
        </td>
    </table>

    <table>
        <tr>
            <th>Try the Model</th>
        </tr>
        <td>
            <p>Try our model on the Google Teachable Machine website!</p>
            <p><a href="https://teachablemachine.withgoogle.com/models/mLma4Xcad/" target=”_blank”>Google Teachable Machine</a></p>
            <p>Also try our model on the p5.js website!</p>
            <p><a href="https://editor.p5js.org/xpha/sketches/igcbSmu79" target=”_blank”>Link to try the model...</a></p>
            <p>GitHub Repository</p>
            <p><a href="https://github.com/xpha-afk/LIS-500-Project-2" target=”_blank”>Link to our GitHub...</a></p>
        </td>
    </table>

    <!-- Footer-->
    <footer>
        <div class="footer-content">
            <p>© 2024 Xai Pha, Josh Gerrits, Fife Salako. All rights reserved.</p>
        </div>
    </footer>
    
</body>
</html>